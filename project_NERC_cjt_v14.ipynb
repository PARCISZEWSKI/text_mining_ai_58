{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba890e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Virtual environments cursos\\Text_Mining\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from simpletransformers.ner import NERModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772ee343",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'NER-test.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13ece074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "1: Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "2: Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "3: Madvillainy is still my favourite MF DOOM record .\n",
      "4: My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance .\n",
      "5: Venus Williams has always been overshadowed by her sister .\n",
      "6: Since Queen Elizabeth died , King Charles has been the head of the British Royal Family .\n",
      "7: I stayed up all night playing Dark Souls again .\n",
      "8: Speaking of great movies - do you remember Once Upon a Time in America ?\n",
      "9: Michael Jordan is considered one of the best players in the history of the NBA .\n",
      "10: They used to call it New Amsterdam before they called it New York .\n",
      "11: MMA is not my favourite , but seeing John Cena is not something you get to do every day .\n",
      "12: OK Computer is supposed to be one of the definitive albums of the '90s .\n",
      "13: Michael Phelps has won over 20 medals at the Olympic Games !\n",
      "14: Ursula von der Leyen is the current president of the European Union Commission .\n"
     ]
    }
   ],
   "source": [
    "sentences_df = df.groupby('sentence_id')['token'].apply(list).reset_index()\n",
    "test_sentences = [\" \".join(tokens) for tokens in sentences_df['token']]\n",
    "\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "    print(f\"{i}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbefd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'If': 'O'},\n",
       "  {\"you're\": 'O'},\n",
       "  {'visiting': 'O'},\n",
       "  {'Paris': 'B-LOC'},\n",
       "  {',': 'O'},\n",
       "  {'make': 'O'},\n",
       "  {'sure': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'see': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Louvre': 'B-ORG'},\n",
       "  {',': 'O'},\n",
       "  {'as': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'exhibit': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Mona': 'B-MISC'},\n",
       "  {'Lisa': 'I-MISC'},\n",
       "  {'!': 'O'}],\n",
       " [{'Amazon': 'B-ORG'},\n",
       "  {',': 'O'},\n",
       "  {'Google': 'B-ORG'},\n",
       "  {'and': 'O'},\n",
       "  {'Meta': 'B-ORG'},\n",
       "  {'control': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'huge': 'O'},\n",
       "  {'share': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'technology': 'O'},\n",
       "  {'market': 'O'},\n",
       "  {'globally': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Did': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'hear': 'O'},\n",
       "  {'Pharoah': 'B-PER'},\n",
       "  {'Sanders': 'I-PER'},\n",
       "  {'recorded': 'O'},\n",
       "  {'an': 'O'},\n",
       "  {'album': 'O'},\n",
       "  {'with': 'O'},\n",
       "  {'Floating': 'B-ORG'},\n",
       "  {'Points': 'I-ORG'},\n",
       "  {'?': 'O'}],\n",
       " [{'Madvillainy': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'still': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {'MF': 'O'},\n",
       "  {'DOOM': 'O'},\n",
       "  {'record': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'My': 'O'},\n",
       "  {'friend': 'O'},\n",
       "  {'Kevin': 'B-PER'},\n",
       "  {'just': 'O'},\n",
       "  {'finished': 'O'},\n",
       "  {'watching': 'O'},\n",
       "  {'Succession': 'B-MISC'},\n",
       "  {',': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {\"won't\": 'O'},\n",
       "  {'stop': 'O'},\n",
       "  {'talking': 'O'},\n",
       "  {'about': 'O'},\n",
       "  {'Kieran': 'B-PER'},\n",
       "  {'Culkin': 'I-PER'},\n",
       "  {\"'s\": 'O'},\n",
       "  {'performance': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Venus': 'B-PER'},\n",
       "  {'Williams': 'I-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'always': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'overshadowed': 'O'},\n",
       "  {'by': 'O'},\n",
       "  {'her': 'O'},\n",
       "  {'sister': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Since': 'O'},\n",
       "  {'Queen': 'O'},\n",
       "  {'Elizabeth': 'B-PER'},\n",
       "  {'died': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'King': 'O'},\n",
       "  {'Charles': 'B-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'head': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'British': 'B-MISC'},\n",
       "  {'Royal': 'O'},\n",
       "  {'Family': 'I-ORG'},\n",
       "  {'.': 'O'}],\n",
       " [{'I': 'O'},\n",
       "  {'stayed': 'O'},\n",
       "  {'up': 'O'},\n",
       "  {'all': 'O'},\n",
       "  {'night': 'O'},\n",
       "  {'playing': 'O'},\n",
       "  {'Dark': 'B-MISC'},\n",
       "  {'Souls': 'I-MISC'},\n",
       "  {'again': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Speaking': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'great': 'O'},\n",
       "  {'movies': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'remember': 'O'},\n",
       "  {'Once': 'B-MISC'},\n",
       "  {'Upon': 'I-MISC'},\n",
       "  {'a': 'I-MISC'},\n",
       "  {'Time': 'I-MISC'},\n",
       "  {'in': 'I-MISC'},\n",
       "  {'America': 'B-LOC'},\n",
       "  {'?': 'O'}],\n",
       " [{'Michael': 'B-PER'},\n",
       "  {'Jordan': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'considered': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'best': 'O'},\n",
       "  {'players': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'history': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'NBA': 'B-ORG'},\n",
       "  {'.': 'O'}],\n",
       " [{'They': 'O'},\n",
       "  {'used': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'call': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-LOC'},\n",
       "  {'Amsterdam': 'I-LOC'},\n",
       "  {'before': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'called': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-LOC'},\n",
       "  {'York': 'I-LOC'},\n",
       "  {'.': 'O'}],\n",
       " [{'MMA': 'B-MISC'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'but': 'O'},\n",
       "  {'seeing': 'O'},\n",
       "  {'John': 'B-PER'},\n",
       "  {'Cena': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'something': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'get': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'every': 'O'},\n",
       "  {'day': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'OK': 'B-ORG'},\n",
       "  {'Computer': 'I-ORG'},\n",
       "  {'is': 'O'},\n",
       "  {'supposed': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'be': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'definitive': 'O'},\n",
       "  {'albums': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {\"'90s\": 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Michael': 'B-PER'},\n",
       "  {'Phelps': 'I-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'won': 'O'},\n",
       "  {'over': 'O'},\n",
       "  {'20': 'O'},\n",
       "  {'medals': 'O'},\n",
       "  {'at': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Olympic': 'B-MISC'},\n",
       "  {'Games': 'I-MISC'},\n",
       "  {'!': 'O'}],\n",
       " [{'Ursula': 'B-PER'},\n",
       "  {'von': 'I-PER'},\n",
       "  {'der': 'I-PER'},\n",
       "  {'Leyen': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'current': 'O'},\n",
       "  {'president': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'European': 'B-ORG'},\n",
       "  {'Union': 'I-ORG'},\n",
       "  {'Commission': 'I-ORG'},\n",
       "  {'.': 'O'}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishmodel = NERModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"dslim/bert-base-NER\",\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel.predict(test_sentences)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0d95b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        B-LOC       0.75      1.00      0.86         3\n",
      "       B-MISC       0.00      0.00      0.00         0\n",
      "        B-ORG       0.75      0.75      0.75         8\n",
      "        B-PER       0.80      0.67      0.73        12\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "        I-LOC       1.00      1.00      1.00         2\n",
      "       I-MISC       0.00      0.00      0.00         0\n",
      "        I-ORG       0.60      0.60      0.60         5\n",
      "        I-PER       1.00      0.69      0.82        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.96      0.99      0.98       159\n",
      "\n",
      "     accuracy                           0.88       216\n",
      "    macro avg       0.53      0.52      0.52       216\n",
      " weighted avg       0.88      0.88      0.87       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "\n",
    "tag_mapping = {}\n",
    "\n",
    "tag_mapping = {\n",
    "    'O': 'O',\n",
    "    'B-LOCATION': 'B-LOC',\n",
    "    'I-LOCATION': 'I-LOC',\n",
    "    'B-ORG': 'B-ORG',\n",
    "    'I-ORG': 'I-ORG',\n",
    "    'B-WORK_OF_ART': 'B-WORK_OF_ART',\n",
    "    'I-WORK_OF_ART': 'I-WORK_OF_ART',\n",
    "    'B-PERSON': 'B-PER',\n",
    "    'I-PERSON': 'I-PER'\n",
    "}\n",
    "\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag'].replace(tag_mapping)\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af35e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "token-by-token check\n",
      "================================================================================\n",
      "Token                     | True Tag        | Predicted Tag   | Check\n",
      "--------------------------------------------------------------------------------\n",
      "If                        | O               | O               | ok\n",
      "you're                    | O               | O               | ok\n",
      "visiting                  | O               | O               | ok\n",
      "Paris                     | B-LOC           | B-LOC           | ok\n",
      ",                         | O               | O               | ok\n",
      "make                      | O               | O               | ok\n",
      "sure                      | O               | O               | ok\n",
      "to                        | O               | O               | ok\n",
      "see                       | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "Louvre                    | B-ORG           | B-ORG           | ok\n",
      ",                         | O               | O               | ok\n",
      "as                        | O               | O               | ok\n",
      "they                      | O               | O               | ok\n",
      "exhibit                   | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "Mona                      | B-WORK_OF_ART   | B-MISC          | not ok\n",
      "Lisa                      | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "!                         | O               | O               | ok\n",
      "Amazon                    | B-ORG           | B-ORG           | ok\n",
      ",                         | O               | O               | ok\n",
      "Google                    | B-ORG           | B-ORG           | ok\n",
      "and                       | O               | O               | ok\n",
      "Meta                      | B-ORG           | B-ORG           | ok\n",
      "control                   | O               | O               | ok\n",
      "a                         | O               | O               | ok\n",
      "huge                      | O               | O               | ok\n",
      "share                     | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "technology                | O               | O               | ok\n",
      "market                    | O               | O               | ok\n",
      "globally                  | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "Did                       | O               | O               | ok\n",
      "you                       | O               | O               | ok\n",
      "hear                      | O               | O               | ok\n",
      "Pharoah                   | B-PER           | B-PER           | ok\n",
      "Sanders                   | I-PER           | I-PER           | ok\n",
      "recorded                  | O               | O               | ok\n",
      "an                        | O               | O               | ok\n",
      "album                     | O               | O               | ok\n",
      "with                      | O               | O               | ok\n",
      "Floating                  | B-PER           | B-ORG           | not ok\n",
      "Points                    | I-PER           | I-ORG           | not ok\n",
      "?                         | O               | O               | ok\n",
      "Madvillainy               | B-WORK_OF_ART   | O               | not ok\n",
      "is                        | O               | O               | ok\n",
      "still                     | O               | O               | ok\n",
      "my                        | O               | O               | ok\n",
      "favourite                 | O               | O               | ok\n",
      "MF                        | B-PER           | O               | not ok\n",
      "DOOM                      | I-PER           | O               | not ok\n",
      "record                    | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "My                        | O               | O               | ok\n",
      "friend                    | O               | O               | ok\n",
      "Kevin                     | B-PER           | B-PER           | ok\n",
      "just                      | O               | O               | ok\n",
      "finished                  | O               | O               | ok\n",
      "watching                  | O               | O               | ok\n",
      "Succession                | B-WORK_OF_ART   | B-MISC          | not ok\n",
      ",                         | O               | O               | ok\n",
      "and                       | O               | O               | ok\n",
      "won't                     | O               | O               | ok\n",
      "stop                      | O               | O               | ok\n",
      "talking                   | O               | O               | ok\n",
      "about                     | O               | O               | ok\n",
      "Kieran                    | B-PER           | B-PER           | ok\n",
      "Culkin                    | I-PER           | I-PER           | ok\n",
      "'s                        | O               | O               | ok\n",
      "performance               | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "Venus                     | B-PER           | B-PER           | ok\n",
      "Williams                  | I-PER           | I-PER           | ok\n",
      "has                       | O               | O               | ok\n",
      "always                    | O               | O               | ok\n",
      "been                      | O               | O               | ok\n",
      "overshadowed              | O               | O               | ok\n",
      "by                        | O               | O               | ok\n",
      "her                       | O               | O               | ok\n",
      "sister                    | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "Since                     | O               | O               | ok\n",
      "Queen                     | B-PER           | O               | not ok\n",
      "Elizabeth                 | I-PER           | B-PER           | not ok\n",
      "died                      | O               | O               | ok\n",
      ",                         | O               | O               | ok\n",
      "King                      | B-PER           | O               | not ok\n",
      "Charles                   | I-PER           | B-PER           | not ok\n",
      "has                       | O               | O               | ok\n",
      "been                      | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "head                      | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "British                   | B-ORG           | B-MISC          | not ok\n",
      "Royal                     | I-ORG           | O               | not ok\n",
      "Family                    | I-ORG           | I-ORG           | ok\n",
      ".                         | O               | O               | ok\n",
      "I                         | O               | O               | ok\n",
      "stayed                    | O               | O               | ok\n",
      "up                        | O               | O               | ok\n",
      "all                       | O               | O               | ok\n",
      "night                     | O               | O               | ok\n",
      "playing                   | O               | O               | ok\n",
      "Dark                      | B-WORK_OF_ART   | B-MISC          | not ok\n",
      "Souls                     | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "again                     | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "Speaking                  | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "great                     | O               | O               | ok\n",
      "movies                    | O               | O               | ok\n",
      "-                         | O               | O               | ok\n",
      "do                        | O               | O               | ok\n",
      "you                       | O               | O               | ok\n",
      "remember                  | O               | O               | ok\n",
      "Once                      | B-WORK_OF_ART   | B-MISC          | not ok\n",
      "Upon                      | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "a                         | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "Time                      | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "in                        | I-WORK_OF_ART   | I-MISC          | not ok\n",
      "America                   | I-WORK_OF_ART   | B-LOC           | not ok\n",
      "?                         | O               | O               | ok\n",
      "Michael                   | B-PER           | B-PER           | ok\n",
      "Jordan                    | I-PER           | I-PER           | ok\n",
      "is                        | O               | O               | ok\n",
      "considered                | O               | O               | ok\n",
      "one                       | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "best                      | O               | O               | ok\n",
      "players                   | O               | O               | ok\n",
      "in                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "history                   | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "NBA                       | B-ORG           | B-ORG           | ok\n",
      ".                         | O               | O               | ok\n",
      "They                      | O               | O               | ok\n",
      "used                      | O               | O               | ok\n",
      "to                        | O               | O               | ok\n",
      "call                      | O               | O               | ok\n",
      "it                        | O               | O               | ok\n",
      "New                       | B-LOC           | B-LOC           | ok\n",
      "Amsterdam                 | I-LOC           | I-LOC           | ok\n",
      "before                    | O               | O               | ok\n",
      "they                      | O               | O               | ok\n",
      "called                    | O               | O               | ok\n",
      "it                        | O               | O               | ok\n",
      "New                       | B-LOC           | B-LOC           | ok\n",
      "York                      | I-LOC           | I-LOC           | ok\n",
      ".                         | O               | O               | ok\n",
      "MMA                       | O               | B-MISC          | not ok\n",
      "is                        | O               | O               | ok\n",
      "not                       | O               | O               | ok\n",
      "my                        | O               | O               | ok\n",
      "favourite                 | O               | O               | ok\n",
      ",                         | O               | O               | ok\n",
      "but                       | O               | O               | ok\n",
      "seeing                    | O               | O               | ok\n",
      "John                      | B-PER           | B-PER           | ok\n",
      "Cena                      | I-PER           | I-PER           | ok\n",
      "is                        | O               | O               | ok\n",
      "not                       | O               | O               | ok\n",
      "something                 | O               | O               | ok\n",
      "you                       | O               | O               | ok\n",
      "get                       | O               | O               | ok\n",
      "to                        | O               | O               | ok\n",
      "do                        | O               | O               | ok\n",
      "every                     | O               | O               | ok\n",
      "day                       | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "OK                        | B-WORK_OF_ART   | B-ORG           | not ok\n",
      "Computer                  | I-WORK_OF_ART   | I-ORG           | not ok\n",
      "is                        | O               | O               | ok\n",
      "supposed                  | O               | O               | ok\n",
      "to                        | O               | O               | ok\n",
      "be                        | O               | O               | ok\n",
      "one                       | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "definitive                | O               | O               | ok\n",
      "albums                    | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "'90s                      | O               | O               | ok\n",
      ".                         | O               | O               | ok\n",
      "Michael                   | B-PER           | B-PER           | ok\n",
      "Phelps                    | I-PER           | I-PER           | ok\n",
      "has                       | O               | O               | ok\n",
      "won                       | O               | O               | ok\n",
      "over                      | O               | O               | ok\n",
      "20                        | O               | O               | ok\n",
      "medals                    | O               | O               | ok\n",
      "at                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "Olympic                   | B-ORG           | B-MISC          | not ok\n",
      "Games                     | I-ORG           | I-MISC          | not ok\n",
      "!                         | O               | O               | ok\n",
      "Ursula                    | B-PER           | B-PER           | ok\n",
      "von                       | I-PER           | I-PER           | ok\n",
      "der                       | I-PER           | I-PER           | ok\n",
      "Leyen                     | I-PER           | I-PER           | ok\n",
      "is                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "current                   | O               | O               | ok\n",
      "president                 | O               | O               | ok\n",
      "of                        | O               | O               | ok\n",
      "the                       | O               | O               | ok\n",
      "European                  | B-ORG           | B-ORG           | ok\n",
      "Union                     | I-ORG           | I-ORG           | ok\n",
      "Commission                | I-ORG           | I-ORG           | ok\n",
      ".                         | O               | O               | ok\n",
      "number of errors: 27\n"
     ]
    }
   ],
   "source": [
    "token_column_in_df_true = 'token'\n",
    "tokens = df_true[token_column_in_df_true].tolist()\n",
    "\n",
    "print (\"\\n\" + \"=\"*80)\n",
    "print(\"token-by-token check\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Token':<25} | {'True Tag':<15} | {'Predicted Tag':<15} | Check\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "errors = 0\n",
    "for i in range(len(y_true_flat)):\n",
    "    token = str(tokens[i])\n",
    "    true_tag = str(y_true_flat[i])\n",
    "    pred_tag = str(y_pred_flat[i])\n",
    "    \n",
    "    if true_tag == pred_tag:\n",
    "        status = \"ok\"\n",
    "    else:\n",
    "        status = \"not ok\"\n",
    "        errors += 1\n",
    "    print(f\"{token:<25} | {true_tag:<15} | {pred_tag:<15} | {status}\")\n",
    "    \n",
    "print(f\"number of errors: {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following cells contain the code run to try other transformer models for the NERC technique. Due to their relatively underwhelming\n",
    "#performance, they were not considered for the purpose of final results analysis (only the bert-base-NER model, whose results are in the\n",
    "# code cells above, was considered for final results analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c59eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels defined: 37\n"
     ]
    }
   ],
   "source": [
    "#Configuration of the RobertaForTokenClassification model with a classification head suitable for 37 labels for models trained on ontonotes.\n",
    "\n",
    "ontonotes_labels = [\n",
    "    \"O\",\n",
    "    \"B-CARDINAL\", \"I-CARDINAL\", \"B-DATE\", \"I-DATE\", \"B-EVENT\", \"I-EVENT\",\n",
    "    \"B-FAC\", \"I-FAC\", \"B-GPE\", \"I-GPE\", \"B-LANGUAGE\", \"I-LANGUAGE\",\n",
    "    \"B-LAW\", \"I-LAW\", \"B-LOC\", \"I-LOC\", \"B-MONEY\", \"I-MONEY\",\n",
    "    \"B-NORP\", \"I-NORP\", \"B-ORDINAL\", \"I-ORDINAL\", \"B-ORG\", \"I-ORG\",\n",
    "    \"B-PERCENT\", \"I-PERCENT\", \"B-PERSON\", \"I-PERSON\", \"B-PRODUCT\", \"I-PRODUCT\",\n",
    "    \"B-QUANTITY\", \"I-QUANTITY\", \"B-TIME\", \"I-TIME\", \"B-WORK_OF_ART\", \"I-WORK_OF_ART\"\n",
    "]\n",
    "\n",
    "print(f\"Number of labels defined: {len(ontonotes_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbfcd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.44s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'If': 'O'},\n",
       "  {\"you're\": 'O'},\n",
       "  {'visiting': 'O'},\n",
       "  {'Paris': 'B-FAC'},\n",
       "  {',': 'O'},\n",
       "  {'make': 'O'},\n",
       "  {'sure': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'see': 'O'},\n",
       "  {'the': 'I-NORP'},\n",
       "  {'Louvre': 'I-QUANTITY'},\n",
       "  {',': 'O'},\n",
       "  {'as': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'exhibit': 'O'},\n",
       "  {'the': 'I-MONEY'},\n",
       "  {'Mona': 'B-NORP'},\n",
       "  {'Lisa': 'B-NORP'},\n",
       "  {'!': 'O'}],\n",
       " [{'Amazon': 'B-LANGUAGE'},\n",
       "  {',': 'O'},\n",
       "  {'Google': 'B-LANGUAGE'},\n",
       "  {'and': 'O'},\n",
       "  {'Meta': 'B-LANGUAGE'},\n",
       "  {'control': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'huge': 'O'},\n",
       "  {'share': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'technology': 'O'},\n",
       "  {'market': 'O'},\n",
       "  {'globally': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Did': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'hear': 'O'},\n",
       "  {'Pharoah': 'I-DATE'},\n",
       "  {'Sanders': 'B-EVENT'},\n",
       "  {'recorded': 'O'},\n",
       "  {'an': 'O'},\n",
       "  {'album': 'O'},\n",
       "  {'with': 'O'},\n",
       "  {'Floating': 'I-MONEY'},\n",
       "  {'Points': 'B-NORP'},\n",
       "  {'?': 'O'}],\n",
       " [{'Madvillainy': 'I-MONEY'},\n",
       "  {'is': 'O'},\n",
       "  {'still': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {'MF': 'B-LANGUAGE'},\n",
       "  {'DOOM': 'I-LANGUAGE'},\n",
       "  {'record': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'My': 'O'},\n",
       "  {'friend': 'O'},\n",
       "  {'Kevin': 'I-DATE'},\n",
       "  {'just': 'O'},\n",
       "  {'finished': 'O'},\n",
       "  {'watching': 'O'},\n",
       "  {'Succession': 'I-MONEY'},\n",
       "  {',': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {\"won't\": 'O'},\n",
       "  {'stop': 'O'},\n",
       "  {'talking': 'O'},\n",
       "  {'about': 'O'},\n",
       "  {'Kieran': 'I-DATE'},\n",
       "  {'Culkin': 'B-EVENT'},\n",
       "  {\"'s\": 'B-EVENT'},\n",
       "  {'performance': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Venus': 'I-DATE'},\n",
       "  {'Williams': 'B-EVENT'},\n",
       "  {'has': 'O'},\n",
       "  {'always': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'overshadowed': 'O'},\n",
       "  {'by': 'O'},\n",
       "  {'her': 'O'},\n",
       "  {'sister': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Since': 'O'},\n",
       "  {'Queen': 'O'},\n",
       "  {'Elizabeth': 'I-DATE'},\n",
       "  {'died': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'King': 'O'},\n",
       "  {'Charles': 'I-DATE'},\n",
       "  {'has': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'head': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'British': 'I-EVENT'},\n",
       "  {'Royal': 'O'},\n",
       "  {'Family': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'I': 'O'},\n",
       "  {'stayed': 'O'},\n",
       "  {'up': 'O'},\n",
       "  {'all': 'B-ORDINAL'},\n",
       "  {'night': 'B-PRODUCT'},\n",
       "  {'playing': 'O'},\n",
       "  {'Dark': 'I-MONEY'},\n",
       "  {'Souls': 'B-NORP'},\n",
       "  {'again': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Speaking': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'great': 'O'},\n",
       "  {'movies': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'remember': 'O'},\n",
       "  {'Once': 'I-MONEY'},\n",
       "  {'Upon': 'B-NORP'},\n",
       "  {'a': 'B-NORP'},\n",
       "  {'Time': 'B-NORP'},\n",
       "  {'in': 'B-NORP'},\n",
       "  {'America': 'B-NORP'},\n",
       "  {'?': 'O'}],\n",
       " [{'Michael': 'I-DATE'},\n",
       "  {'Jordan': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'considered': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'best': 'O'},\n",
       "  {'players': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'history': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'NBA': 'B-LANGUAGE'},\n",
       "  {'.': 'O'}],\n",
       " [{'They': 'O'},\n",
       "  {'used': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'call': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-FAC'},\n",
       "  {'Amsterdam': 'I-FAC'},\n",
       "  {'before': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'called': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-FAC'},\n",
       "  {'York': 'I-FAC'},\n",
       "  {'.': 'O'}],\n",
       " [{'MMA': 'B-LANGUAGE'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'but': 'O'},\n",
       "  {'seeing': 'O'},\n",
       "  {'John': 'I-DATE'},\n",
       "  {'Cena': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'something': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'get': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'every': 'I-CARDINAL'},\n",
       "  {'day': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'OK': 'I-MONEY'},\n",
       "  {'Computer': 'B-NORP'},\n",
       "  {'is': 'O'},\n",
       "  {'supposed': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'be': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'definitive': 'O'},\n",
       "  {'albums': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'I-CARDINAL'},\n",
       "  {\"'90s\": 'B-DATE'},\n",
       "  {'.': 'O'}],\n",
       " [{'Michael': 'I-DATE'},\n",
       "  {'Phelps': 'B-EVENT'},\n",
       "  {'has': 'O'},\n",
       "  {'won': 'O'},\n",
       "  {'over': 'B-CARDINAL'},\n",
       "  {'20': 'I-ORDINAL'},\n",
       "  {'medals': 'O'},\n",
       "  {'at': 'O'},\n",
       "  {'the': 'I-PRODUCT'},\n",
       "  {'Olympic': 'B-QUANTITY'},\n",
       "  {'Games': 'B-QUANTITY'},\n",
       "  {'!': 'O'}],\n",
       " [{'Ursula': 'I-DATE'},\n",
       "  {'von': 'B-EVENT'},\n",
       "  {'der': 'B-EVENT'},\n",
       "  {'Leyen': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'current': 'O'},\n",
       "  {'president': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'B-LANGUAGE'},\n",
       "  {'European': 'I-LANGUAGE'},\n",
       "  {'Union': 'I-LANGUAGE'},\n",
       "  {'Commission': 'I-LANGUAGE'},\n",
       "  {'.': 'O'}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishmodel_3 = NERModel(\n",
    "    model_type=\"roberta\",\n",
    "    model_name=\"guishe/nuner-v1_ontonotes5\",\n",
    "    labels=ontonotes_labels,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_3.predict(test_sentences)\n",
    "predictions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07395bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-CARDINAL       0.00      0.00      0.00         0\n",
      "       B-DATE       0.00      0.00      0.00         0\n",
      "      B-EVENT       0.00      0.00      0.00         0\n",
      "        B-FAC       0.00      0.00      0.00         0\n",
      "   B-LANGUAGE       0.00      0.00      0.00         0\n",
      "        B-LOC       0.00      0.00      0.00         3\n",
      "       B-NORP       0.00      0.00      0.00         0\n",
      "    B-ORDINAL       0.00      0.00      0.00         0\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "    B-PRODUCT       0.00      0.00      0.00         0\n",
      "   B-QUANTITY       0.00      0.00      0.00         0\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "   I-CARDINAL       0.00      0.00      0.00         0\n",
      "       I-DATE       0.00      0.00      0.00         0\n",
      "      I-EVENT       0.00      0.00      0.00         0\n",
      "        I-FAC       0.00      0.00      0.00         0\n",
      "   I-LANGUAGE       0.00      0.00      0.00         0\n",
      "        I-LOC       0.00      0.00      0.00         2\n",
      "      I-MONEY       0.00      0.00      0.00         0\n",
      "       I-NORP       0.00      0.00      0.00         0\n",
      "    I-ORDINAL       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         5\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "    I-PRODUCT       0.00      0.00      0.00         0\n",
      "   I-QUANTITY       0.00      0.00      0.00         0\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.97      0.92      0.94       159\n",
      "\n",
      "     accuracy                           0.68       216\n",
      "    macro avg       0.03      0.03      0.03       216\n",
      " weighted avg       0.72      0.68      0.70       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "tag_mapping = {}\n",
    "\n",
    "tag_mapping = {\n",
    "    'O': 'O',\n",
    "    'B-LOCATION': 'B-LOC',\n",
    "    'I-LOCATION': 'I-LOC',\n",
    "    'B-ORG': 'B-ORG',\n",
    "    'I-ORG': 'I-ORG',\n",
    "    'B-WORK_OF_ART': 'B-WORK_OF_ART',\n",
    "    'I-WORK_OF_ART': 'I-WORK_OF_ART',\n",
    "    'B-PERSON': 'B-PERSON',\n",
    "    'I-PERSON': 'I-PERSON'\n",
    "}\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag'].replace(tag_mapping)\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9419da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.17s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00, 20.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'If': 'O'},\n",
       "  {\"you're\": 'O'},\n",
       "  {'visiting': 'O'},\n",
       "  {'Paris': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'make': 'O'},\n",
       "  {'sure': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'see': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Louvre': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'as': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'exhibit': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Mona': 'O'},\n",
       "  {'Lisa': 'O'},\n",
       "  {'!': 'O'}],\n",
       " [{'Amazon': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'Google': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {'Meta': 'O'},\n",
       "  {'control': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'huge': 'O'},\n",
       "  {'share': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'technology': 'O'},\n",
       "  {'market': 'O'},\n",
       "  {'globally': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Did': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'hear': 'O'},\n",
       "  {'Pharoah': 'O'},\n",
       "  {'Sanders': 'O'},\n",
       "  {'recorded': 'O'},\n",
       "  {'an': 'O'},\n",
       "  {'album': 'O'},\n",
       "  {'with': 'O'},\n",
       "  {'Floating': 'O'},\n",
       "  {'Points': 'O'},\n",
       "  {'?': 'O'}],\n",
       " [{'Madvillainy': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'still': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {'MF': 'O'},\n",
       "  {'DOOM': 'O'},\n",
       "  {'record': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'My': 'O'},\n",
       "  {'friend': 'O'},\n",
       "  {'Kevin': 'O'},\n",
       "  {'just': 'O'},\n",
       "  {'finished': 'O'},\n",
       "  {'watching': 'O'},\n",
       "  {'Succession': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {\"won't\": 'O'},\n",
       "  {'stop': 'O'},\n",
       "  {'talking': 'O'},\n",
       "  {'about': 'O'},\n",
       "  {'Kieran': 'O'},\n",
       "  {'Culkin': 'O'},\n",
       "  {\"'s\": 'O'},\n",
       "  {'performance': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Venus': 'O'},\n",
       "  {'Williams': 'O'},\n",
       "  {'has': 'O'},\n",
       "  {'always': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'overshadowed': 'O'},\n",
       "  {'by': 'O'},\n",
       "  {'her': 'O'},\n",
       "  {'sister': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Since': 'O'},\n",
       "  {'Queen': 'O'},\n",
       "  {'Elizabeth': 'O'},\n",
       "  {'died': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'King': 'O'},\n",
       "  {'Charles': 'O'},\n",
       "  {'has': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'head': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'British': 'O'},\n",
       "  {'Royal': 'O'},\n",
       "  {'Family': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'I': 'O'},\n",
       "  {'stayed': 'O'},\n",
       "  {'up': 'O'},\n",
       "  {'all': 'O'},\n",
       "  {'night': 'O'},\n",
       "  {'playing': 'O'},\n",
       "  {'Dark': 'O'},\n",
       "  {'Souls': 'O'},\n",
       "  {'again': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Speaking': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'great': 'O'},\n",
       "  {'movies': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'remember': 'O'},\n",
       "  {'Once': 'O'},\n",
       "  {'Upon': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'Time': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'America': 'O'},\n",
       "  {'?': 'O'}],\n",
       " [{'Michael': 'O'},\n",
       "  {'Jordan': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'considered': 'O'},\n",
       "  {'one': 'B-CARDINAL'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'best': 'O'},\n",
       "  {'players': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'history': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'NBA': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'They': 'O'},\n",
       "  {'used': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'call': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'O'},\n",
       "  {'Amsterdam': 'O'},\n",
       "  {'before': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'called': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'O'},\n",
       "  {'York': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'MMA': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'but': 'O'},\n",
       "  {'seeing': 'O'},\n",
       "  {'John': 'O'},\n",
       "  {'Cena': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'something': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'get': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'every': 'O'},\n",
       "  {'day': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'OK': 'O'},\n",
       "  {'Computer': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'supposed': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'be': 'O'},\n",
       "  {'one': 'B-CARDINAL'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'definitive': 'O'},\n",
       "  {'albums': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'I-CARDINAL'},\n",
       "  {\"'90s\": 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Michael': 'O'},\n",
       "  {'Phelps': 'O'},\n",
       "  {'has': 'O'},\n",
       "  {'won': 'O'},\n",
       "  {'over': 'O'},\n",
       "  {'20': 'B-CARDINAL'},\n",
       "  {'medals': 'O'},\n",
       "  {'at': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Olympic': 'O'},\n",
       "  {'Games': 'O'},\n",
       "  {'!': 'O'}],\n",
       " [{'Ursula': 'I-DATE'},\n",
       "  {'von': 'I-DATE'},\n",
       "  {'der': 'B-EVENT'},\n",
       "  {'Leyen': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'current': 'O'},\n",
       "  {'president': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'European': 'O'},\n",
       "  {'Union': 'O'},\n",
       "  {'Commission': 'O'},\n",
       "  {'.': 'O'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishmodel_4 = NERModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"arnabdhar/bert-tiny-ontonotes\",\n",
    "    labels=ontonotes_labels,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_4.predict(test_sentences)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7729c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-CARDINAL       0.00      0.00      0.00         0\n",
      "      B-EVENT       0.00      0.00      0.00         0\n",
      "        B-LOC       0.00      0.00      0.00         3\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "   I-CARDINAL       0.00      0.00      0.00         0\n",
      "       I-DATE       0.00      0.00      0.00         0\n",
      "        I-LOC       0.00      0.00      0.00         2\n",
      "        I-ORG       0.00      0.00      0.00         5\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.75      0.97      0.84       159\n",
      "\n",
      "     accuracy                           0.72       216\n",
      "    macro avg       0.06      0.07      0.06       216\n",
      " weighted avg       0.55      0.72      0.62       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "tag_mapping = {}\n",
    "\n",
    "tag_mapping = {\n",
    "    'O': 'O',\n",
    "    'B-LOCATION': 'B-LOC',\n",
    "    'I-LOCATION': 'I-LOC',\n",
    "    'B-ORG': 'B-ORG',\n",
    "    'I-ORG': 'I-ORG',\n",
    "    'B-WORK_OF_ART': 'B-WORK_OF_ART',\n",
    "    'I-WORK_OF_ART': 'I-WORK_OF_ART',\n",
    "    'B-PERSON': 'B-PERSON',\n",
    "    'I-PERSON': 'I-PERSON'\n",
    "}\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag'].replace(tag_mapping)\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c059b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.56s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'If': 'O'},\n",
       "  {\"you're\": 'O'},\n",
       "  {'visiting': 'O'},\n",
       "  {'Paris': 'B-FAC'},\n",
       "  {',': 'O'},\n",
       "  {'make': 'O'},\n",
       "  {'sure': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'see': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Louvre': 'I-NORP'},\n",
       "  {',': 'O'},\n",
       "  {'as': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'exhibit': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Mona': 'O'},\n",
       "  {'Lisa': 'O'},\n",
       "  {'!': 'O'}],\n",
       " [{'Amazon': 'B-LANGUAGE'},\n",
       "  {',': 'O'},\n",
       "  {'Google': 'B-LANGUAGE'},\n",
       "  {'and': 'O'},\n",
       "  {'Meta': 'B-LANGUAGE'},\n",
       "  {'control': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'huge': 'O'},\n",
       "  {'share': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'technology': 'O'},\n",
       "  {'market': 'O'},\n",
       "  {'globally': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Did': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'hear': 'O'},\n",
       "  {'Pharoah': 'O'},\n",
       "  {'Sanders': 'O'},\n",
       "  {'recorded': 'O'},\n",
       "  {'an': 'O'},\n",
       "  {'album': 'O'},\n",
       "  {'with': 'O'},\n",
       "  {'Floating': 'O'},\n",
       "  {'Points': 'O'},\n",
       "  {'?': 'O'}],\n",
       " [{'Madvillainy': 'O'},\n",
       "  {'is': 'O'},\n",
       "  {'still': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {'MF': 'O'},\n",
       "  {'DOOM': 'O'},\n",
       "  {'record': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'My': 'O'},\n",
       "  {'friend': 'O'},\n",
       "  {'Kevin': 'I-DATE'},\n",
       "  {'just': 'O'},\n",
       "  {'finished': 'O'},\n",
       "  {'watching': 'O'},\n",
       "  {'Succession': 'I-MONEY'},\n",
       "  {',': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {\"won't\": 'O'},\n",
       "  {'stop': 'O'},\n",
       "  {'talking': 'O'},\n",
       "  {'about': 'O'},\n",
       "  {'Kieran': 'I-DATE'},\n",
       "  {'Culkin': 'B-EVENT'},\n",
       "  {\"'s\": 'B-EVENT'},\n",
       "  {'performance': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Venus': 'I-DATE'},\n",
       "  {'Williams': 'O'},\n",
       "  {'has': 'O'},\n",
       "  {'always': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'overshadowed': 'O'},\n",
       "  {'by': 'O'},\n",
       "  {'her': 'O'},\n",
       "  {'sister': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Since': 'O'},\n",
       "  {'Queen': 'O'},\n",
       "  {'Elizabeth': 'O'},\n",
       "  {'died': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'King': 'O'},\n",
       "  {'Charles': 'I-DATE'},\n",
       "  {'has': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'head': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'British': 'O'},\n",
       "  {'Royal': 'O'},\n",
       "  {'Family': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'I': 'O'},\n",
       "  {'stayed': 'O'},\n",
       "  {'up': 'O'},\n",
       "  {'all': 'O'},\n",
       "  {'night': 'O'},\n",
       "  {'playing': 'O'},\n",
       "  {'Dark': 'O'},\n",
       "  {'Souls': 'O'},\n",
       "  {'again': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Speaking': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'great': 'O'},\n",
       "  {'movies': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'remember': 'O'},\n",
       "  {'Once': 'O'},\n",
       "  {'Upon': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'Time': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'America': 'O'},\n",
       "  {'?': 'O'}],\n",
       " [{'Michael': 'I-DATE'},\n",
       "  {'Jordan': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'considered': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'best': 'O'},\n",
       "  {'players': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'history': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'NBA': 'B-LANGUAGE'},\n",
       "  {'.': 'O'}],\n",
       " [{'They': 'O'},\n",
       "  {'used': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'call': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-FAC'},\n",
       "  {'Amsterdam': 'I-FAC'},\n",
       "  {'before': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'called': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'B-FAC'},\n",
       "  {'York': 'I-FAC'},\n",
       "  {'.': 'O'}],\n",
       " [{'MMA': 'I-MONEY'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'but': 'O'},\n",
       "  {'seeing': 'O'},\n",
       "  {'John': 'I-DATE'},\n",
       "  {'Cena': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'something': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'get': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'every': 'O'},\n",
       "  {'day': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'OK': 'I-MONEY'},\n",
       "  {'Computer': 'B-NORP'},\n",
       "  {'is': 'O'},\n",
       "  {'supposed': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'be': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'definitive': 'O'},\n",
       "  {'albums': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {\"'90s\": 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Michael': 'I-DATE'},\n",
       "  {'Phelps': 'O'},\n",
       "  {'has': 'O'},\n",
       "  {'won': 'O'},\n",
       "  {'over': 'O'},\n",
       "  {'20': 'O'},\n",
       "  {'medals': 'O'},\n",
       "  {'at': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Olympic': 'B-QUANTITY'},\n",
       "  {'Games': 'B-QUANTITY'},\n",
       "  {'!': 'O'}],\n",
       " [{'Ursula': 'I-DATE'},\n",
       "  {'von': 'B-EVENT'},\n",
       "  {'der': 'B-EVENT'},\n",
       "  {'Leyen': 'B-EVENT'},\n",
       "  {'is': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'current': 'O'},\n",
       "  {'president': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'European': 'B-LANGUAGE'},\n",
       "  {'Union': 'I-LANGUAGE'},\n",
       "  {'Commission': 'I-LANGUAGE'},\n",
       "  {'.': 'O'}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishmodel_5 = NERModel(\n",
    "    model_type=\"roberta\",\n",
    "    model_name=\"tner/roberta-large-ontonotes5\",\n",
    "    labels=ontonotes_labels,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_5.predict(test_sentences)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6a2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      B-EVENT       0.00      0.00      0.00         0\n",
      "        B-FAC       0.00      0.00      0.00         0\n",
      "   B-LANGUAGE       0.00      0.00      0.00         0\n",
      "        B-LOC       0.00      0.00      0.00         3\n",
      "       B-NORP       0.00      0.00      0.00         0\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "   B-QUANTITY       0.00      0.00      0.00         0\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "       I-DATE       0.00      0.00      0.00         0\n",
      "        I-FAC       0.00      0.00      0.00         0\n",
      "   I-LANGUAGE       0.00      0.00      0.00         0\n",
      "        I-LOC       0.00      0.00      0.00         2\n",
      "      I-MONEY       0.00      0.00      0.00         0\n",
      "       I-NORP       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         5\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.86      0.99      0.92       159\n",
      "\n",
      "     accuracy                           0.73       216\n",
      "    macro avg       0.05      0.05      0.05       216\n",
      " weighted avg       0.63      0.73      0.68       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "tag_mapping = {}\n",
    "\n",
    "tag_mapping = {\n",
    "    'O': 'O',\n",
    "    'B-LOCATION': 'B-LOC',\n",
    "    'I-LOCATION': 'I-LOC',\n",
    "    'B-ORG': 'B-ORG',\n",
    "    'I-ORG': 'I-ORG',\n",
    "    'B-WORK_OF_ART': 'B-WORK_OF_ART',\n",
    "    'I-WORK_OF_ART': 'I-WORK_OF_ART',\n",
    "    'B-PERSON': 'B-PERSON',\n",
    "    'I-PERSON': 'I-PERSON'\n",
    "}\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag'].replace(tag_mapping)\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "618b4c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.38s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'If': 'O'},\n",
       "  {\"you're\": 'O'},\n",
       "  {'visiting': 'O'},\n",
       "  {'Paris': 'I-LOC'},\n",
       "  {',': 'O'},\n",
       "  {'make': 'O'},\n",
       "  {'sure': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'see': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Louvre': 'I-ORG'},\n",
       "  {',': 'O'},\n",
       "  {'as': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'exhibit': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Mona': 'I-MISC'},\n",
       "  {'Lisa': 'I-MISC'},\n",
       "  {'!': 'O'}],\n",
       " [{'Amazon': 'I-ORG'},\n",
       "  {',': 'O'},\n",
       "  {'Google': 'I-ORG'},\n",
       "  {'and': 'O'},\n",
       "  {'Meta': 'I-ORG'},\n",
       "  {'control': 'O'},\n",
       "  {'a': 'O'},\n",
       "  {'huge': 'O'},\n",
       "  {'share': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'technology': 'O'},\n",
       "  {'market': 'O'},\n",
       "  {'globally': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Did': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'hear': 'O'},\n",
       "  {'Pharoah': 'I-PER'},\n",
       "  {'Sanders': 'I-PER'},\n",
       "  {'recorded': 'O'},\n",
       "  {'an': 'O'},\n",
       "  {'album': 'O'},\n",
       "  {'with': 'O'},\n",
       "  {'Floating': 'I-ORG'},\n",
       "  {'Points': 'I-ORG'},\n",
       "  {'?': 'O'}],\n",
       " [{'Madvillainy': 'I-MISC'},\n",
       "  {'is': 'O'},\n",
       "  {'still': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {'MF': 'I-ORG'},\n",
       "  {'DOOM': 'I-ORG'},\n",
       "  {'record': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'My': 'O'},\n",
       "  {'friend': 'O'},\n",
       "  {'Kevin': 'I-PER'},\n",
       "  {'just': 'O'},\n",
       "  {'finished': 'O'},\n",
       "  {'watching': 'O'},\n",
       "  {'Succession': 'I-MISC'},\n",
       "  {',': 'O'},\n",
       "  {'and': 'O'},\n",
       "  {\"won't\": 'O'},\n",
       "  {'stop': 'O'},\n",
       "  {'talking': 'O'},\n",
       "  {'about': 'O'},\n",
       "  {'Kieran': 'I-PER'},\n",
       "  {'Culkin': 'I-PER'},\n",
       "  {\"'s\": 'O'},\n",
       "  {'performance': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Venus': 'I-PER'},\n",
       "  {'Williams': 'I-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'always': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'overshadowed': 'O'},\n",
       "  {'by': 'O'},\n",
       "  {'her': 'O'},\n",
       "  {'sister': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Since': 'O'},\n",
       "  {'Queen': 'O'},\n",
       "  {'Elizabeth': 'I-PER'},\n",
       "  {'died': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'King': 'I-PER'},\n",
       "  {'Charles': 'I-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'been': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'head': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'British': 'I-MISC'},\n",
       "  {'Royal': 'O'},\n",
       "  {'Family': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'I': 'O'},\n",
       "  {'stayed': 'O'},\n",
       "  {'up': 'O'},\n",
       "  {'all': 'O'},\n",
       "  {'night': 'O'},\n",
       "  {'playing': 'O'},\n",
       "  {'Dark': 'I-MISC'},\n",
       "  {'Souls': 'I-MISC'},\n",
       "  {'again': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Speaking': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'great': 'O'},\n",
       "  {'movies': 'O'},\n",
       "  {'-': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'remember': 'O'},\n",
       "  {'Once': 'I-MISC'},\n",
       "  {'Upon': 'I-MISC'},\n",
       "  {'a': 'I-MISC'},\n",
       "  {'Time': 'I-MISC'},\n",
       "  {'in': 'I-MISC'},\n",
       "  {'America': 'I-MISC'},\n",
       "  {'?': 'O'}],\n",
       " [{'Michael': 'I-PER'},\n",
       "  {'Jordan': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'considered': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'best': 'O'},\n",
       "  {'players': 'O'},\n",
       "  {'in': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'history': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'NBA': 'I-ORG'},\n",
       "  {'.': 'O'}],\n",
       " [{'They': 'O'},\n",
       "  {'used': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'call': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'I-LOC'},\n",
       "  {'Amsterdam': 'I-LOC'},\n",
       "  {'before': 'O'},\n",
       "  {'they': 'O'},\n",
       "  {'called': 'O'},\n",
       "  {'it': 'O'},\n",
       "  {'New': 'I-LOC'},\n",
       "  {'York': 'I-LOC'},\n",
       "  {'.': 'O'}],\n",
       " [{'MMA': 'I-MISC'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'my': 'O'},\n",
       "  {'favourite': 'O'},\n",
       "  {',': 'O'},\n",
       "  {'but': 'O'},\n",
       "  {'seeing': 'O'},\n",
       "  {'John': 'I-PER'},\n",
       "  {'Cena': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'not': 'O'},\n",
       "  {'something': 'O'},\n",
       "  {'you': 'O'},\n",
       "  {'get': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'do': 'O'},\n",
       "  {'every': 'O'},\n",
       "  {'day': 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'OK': 'I-MISC'},\n",
       "  {'Computer': 'I-MISC'},\n",
       "  {'is': 'O'},\n",
       "  {'supposed': 'O'},\n",
       "  {'to': 'O'},\n",
       "  {'be': 'O'},\n",
       "  {'one': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'definitive': 'O'},\n",
       "  {'albums': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {\"'90s\": 'O'},\n",
       "  {'.': 'O'}],\n",
       " [{'Michael': 'I-PER'},\n",
       "  {'Phelps': 'I-PER'},\n",
       "  {'has': 'O'},\n",
       "  {'won': 'O'},\n",
       "  {'over': 'O'},\n",
       "  {'20': 'O'},\n",
       "  {'medals': 'O'},\n",
       "  {'at': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'Olympic': 'I-MISC'},\n",
       "  {'Games': 'I-MISC'},\n",
       "  {'!': 'O'}],\n",
       " [{'Ursula': 'I-PER'},\n",
       "  {'von': 'I-PER'},\n",
       "  {'der': 'I-PER'},\n",
       "  {'Leyen': 'I-PER'},\n",
       "  {'is': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'current': 'O'},\n",
       "  {'president': 'O'},\n",
       "  {'of': 'O'},\n",
       "  {'the': 'O'},\n",
       "  {'European': 'I-ORG'},\n",
       "  {'Union': 'I-ORG'},\n",
       "  {'Commission': 'I-ORG'},\n",
       "  {'.': 'O'}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishmodel_6 = NERModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_6.predict(test_sentences)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144e3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-LOCATION       0.00      0.00      0.00         3\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "        I-LOC       0.00      0.00      0.00         0\n",
      "   I-LOCATION       0.00      0.00      0.00         2\n",
      "       I-MISC       0.00      0.00      0.00         0\n",
      "        I-ORG       0.17      0.40      0.24         5\n",
      "        I-PER       0.00      0.00      0.00         0\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.98      0.99      0.99       159\n",
      "\n",
      "     accuracy                           0.74       216\n",
      "    macro avg       0.10      0.12      0.10       216\n",
      " weighted avg       0.73      0.74      0.73       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag']\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81306c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-CARDINAL       0.00      0.00      0.00         0\n",
      "       B-DATE       0.00      0.00      0.00         0\n",
      "      B-EVENT       0.00      0.00      0.00         0\n",
      "   B-LOCATION       0.00      0.00      0.00         3\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "   I-CARDINAL       0.00      0.00      0.00         0\n",
      "       I-DATE       0.00      0.00      0.00         0\n",
      "   I-LOCATION       0.00      0.00      0.00         2\n",
      "    I-ORDINAL       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         5\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.75      0.97      0.84       159\n",
      "\n",
      "     accuracy                           0.72       216\n",
      "    macro avg       0.05      0.06      0.06       216\n",
      " weighted avg       0.55      0.72      0.62       216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "englishmodel_7 = NERModel(\n",
    "    model_type=\"distilbert\",\n",
    "    model_name=\"cgensheimer/claims-data-model\",\n",
    "    labels=ontonotes_labels,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_7.predict(test_sentences)\n",
    "predictions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag']\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7c0afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.52s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted tages: 216\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   B-LOCATION       0.00      0.00      0.00         3\n",
      "       B-MISC       0.00      0.00      0.00         0\n",
      "        B-ORG       0.00      0.00      0.00         8\n",
      "     B-PERSON       0.00      0.00      0.00        12\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         6\n",
      "   I-LOCATION       0.00      0.00      0.00         2\n",
      "       I-MISC       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         5\n",
      "     I-PERSON       0.00      0.00      0.00        13\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         8\n",
      "            O       0.75      1.00      0.86       159\n",
      "\n",
      "     accuracy                           0.74       216\n",
      "    macro avg       0.07      0.09      0.08       216\n",
      " weighted avg       0.55      0.74      0.63       216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "englishmodel_8 = NERModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"sartajbhuvaji/bert-named-entity-recognition\",\n",
    "    #labels=ontonotes_labels,\n",
    "    use_cuda=False\n",
    ")\n",
    "\n",
    "predictions, raw_outputs = englishmodel_8.predict(test_sentences)\n",
    "predictions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred_flat = []\n",
    "for sentence_predictions in predictions:\n",
    "    for token_prediction_dict in sentence_predictions:\n",
    "        y_pred_flat.append(list(token_prediction_dict.values())[0])\n",
    "\n",
    "print(f\"Number of predicted tages: {len(y_pred_flat)}\")\n",
    "\n",
    "file_path = 'NER-test.tsv'\n",
    "df_true = pd.read_csv(file_path, sep='\\t', quoting=3)\n",
    "\n",
    "df_true['mapped_BIO_NER_tag'] = df_true['BIO_NER_tag']\n",
    "y_true_flat=df_true['mapped_BIO_NER_tag'].tolist()\n",
    "\n",
    "if len(y_true_flat) == len(y_pred_flat):\n",
    "        all_labels = sorted(list(set(y_true_flat + y_pred_flat)))\n",
    "        \n",
    "        report = classification_report(\n",
    "            y_true_flat,\n",
    "            y_pred_flat,\n",
    "            labels=all_labels,\n",
    "            digits=2,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: Length mismatch between true and predicted labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
