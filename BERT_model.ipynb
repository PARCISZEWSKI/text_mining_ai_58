{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JjBo0pOnpetq",
        "outputId": "3d8742bf-db16-4247-d2ea-6e26f97ea04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub[cli] in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (0.32.2)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (6.0.2)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (1.1.2)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface_hub[cli]) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.51)\n",
            "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->huggingface_hub[cli]) (2025.4.26)\n",
            "Requirement already satisfied: transformers in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (3.6.0)\n",
            "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (2.2.3)\n",
            "Requirement already satisfied: torch in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: simpletransformers in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (0.70.1)\n",
            "Requirement already satisfied: numpy in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (1.26.4)\n",
            "Requirement already satisfied: requests in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (4.67.1)\n",
            "Requirement already satisfied: regex in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (2024.11.6)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (4.51.3)\n",
            "Requirement already satisfied: datasets in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (3.6.0)\n",
            "Requirement already satisfied: scipy in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (1.6.1)\n",
            "Requirement already satisfied: seqeval in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (2.19.0)\n",
            "Requirement already satisfied: tensorboardx in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (2.6.2.2)\n",
            "Requirement already satisfied: pandas in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (2.2.3)\n",
            "Requirement already satisfied: tokenizers in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (0.21.1)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (0.19.11)\n",
            "Requirement already satisfied: streamlit in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (1.45.1)\n",
            "Requirement already satisfied: sentencepiece in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: filelock in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.32.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->simpletransformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->simpletransformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.31.0->simpletransformers) (1.1.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (6.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.0)\n",
            "Requirement already satisfied: pydantic<3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (2.11.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (78.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pydantic<3->wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->simpletransformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->simpletransformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->simpletransformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from requests->simpletransformers) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets->simpletransformers) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (3.11.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers) (1.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas->simpletransformers) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas->simpletransformers) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from pandas->simpletransformers) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.5.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (11.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (1.39.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit->simpletransformers) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.25.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/miniconda3/envs/textmining/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"huggingface_hub[cli]\"\n",
        "!pip install transformers datasets scikit-learn pandas torch\n",
        "!pip install simpletransformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKpVX7LXo5eh"
      },
      "source": [
        "# **imports and initial steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SKXVv7yHowvf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import os # for movies folders\n",
        "\n",
        "try:\n",
        "  nltk.data.find('tokenizers/punkt')\n",
        "  nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('punkt_tab')\n",
        "\n",
        "def segment_into_sentences(text):\n",
        "  if pd.isna(text) or text.strip() == \"\":\n",
        "    return []\n",
        "  return nltk.sent_tokenize(str(text))\n",
        "\n",
        "all_sentences_and_labels = [] # store final dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cz8KVaD3iQb"
      },
      "source": [
        "# **PROCESSING BOOKS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJz5Kwjdsqrs",
        "outputId": "5f43392e-f4f8-40b2-e320-9bd61e7e4076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded book reviews from: /Users/augustincoman/University/Text Mining/final project/archive-3/book-reviews.csv\n",
            "processed 5000 book reviews.\n"
          ]
        }
      ],
      "source": [
        "books_csv_path = \"/Users/augustincoman/University/Text Mining/final project/archive-3/book-reviews.csv\"\n",
        "book_text_column = 'ReviewContent'\n",
        "\n",
        "try:\n",
        "  df_books = pd.read_csv(books_csv_path, encoding='latin1')\n",
        "  print(f\"loaded book reviews from: {books_csv_path}\")\n",
        "\n",
        "  for index, row in df_books.iterrows():\n",
        "    # print(\"entered print\")\n",
        "    review_text = row[book_text_column]\n",
        "    # print(\"got review text\")\n",
        "    sentences = segment_into_sentences(review_text)\n",
        "    # print(\"got sentences\")\n",
        "    for sentence in sentences:\n",
        "      # print(\" entered inner for loop\")\n",
        "      all_sentences_and_labels.append({'text': sentence, 'label': 'book'})\n",
        "      # print(\"added text to df\")\n",
        "  print(f\"processed {len(df_books)} book reviews.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(f\"file not found: {books_csv_path}\")\n",
        "except KeyError:\n",
        "  print(f\"column not found: {book_text_column}\")\n",
        "except Exception as e:\n",
        "  print(f\"error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRLe0syT7h3K"
      },
      "source": [
        "# **PROCESSING MOVIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rCEikuY7gCQ",
        "outputId": "de59c03e-86c8-4f4e-8be8-e7abed7b24b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing movie reviews from: /Users/augustincoman/University/Text Mining/final project/movie-training-set-polarity/pos\n",
            "Processing movie reviews from: /Users/augustincoman/University/Text Mining/final project/movie-training-set-polarity/neg\n",
            "Processed 2000 movie reviews.\n"
          ]
        }
      ],
      "source": [
        "base_movie_review_folder_path = \"/Users/augustincoman/University/Text Mining/final project/movie-training-set-polarity\"\n",
        "review_folders = ['pos', 'neg']\n",
        "\n",
        "movie_reviews_processed_count = 0\n",
        "for folder_name in review_folders:\n",
        "  folder_path = os.path.join(base_movie_review_folder_path, folder_name)\n",
        "  if not os.path.isdir(folder_path):\n",
        "      print(f\"Warning: Movie review folder not found: {folder_path}\")\n",
        "      continue\n",
        "\n",
        "  print(f\"Processing movie reviews from: {folder_path}\")\n",
        "  for filename in os.listdir(folder_path):\n",
        "      if filename.endswith(\".txt\"):\n",
        "          file_path = os.path.join(folder_path, filename)\n",
        "          try:\n",
        "              with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                  review_text = f.read()\n",
        "\n",
        "              sentences = segment_into_sentences(review_text)\n",
        "              for sentence in sentences:\n",
        "                  all_sentences_and_labels.append({'text': sentence, 'label': 'movie'})\n",
        "              movie_reviews_processed_count += 1\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing file {file_path}: {e}\")\n",
        "print(f\"Processed {movie_reviews_processed_count} movie reviews.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KITYVKS09CZq"
      },
      "source": [
        "# **PROCESSING SPORTS ARTICLES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQGNkdwu9CGW",
        "outputId": "8b3e5fc4-1f3f-4156-f683-4c53c4f7139b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sports data from: hf://datasets/datadreamer-dev/cnn_dailymail_sports/data/train-00000-of-00001.parquet\n",
            "Successfully loaded sports data.\n",
            "Columns in sports dataset: ['article', 'highlights', 'id']\n",
            "Processed 47 sports articles/entries.\n"
          ]
        }
      ],
      "source": [
        "sports_data_hf_path = \"hf://datasets/datadreamer-dev/cnn_dailymail_sports/data/train-00000-of-00001.parquet\"\n",
        "\n",
        "try:\n",
        "    print(f\"Loading sports data from: {sports_data_hf_path}\")\n",
        "    df_sports = pd.read_parquet(sports_data_hf_path)\n",
        "    print(\"Successfully loaded sports data.\")\n",
        "\n",
        "    print(f\"Columns in sports dataset: {df_sports.columns.tolist()}\")\n",
        "\n",
        "    sports_text_column = 'article'\n",
        "\n",
        "    if sports_text_column not in df_sports.columns:\n",
        "        print(f\"ERROR: Column '{sports_text_column}' not found in the sports DataFrame.\")\n",
        "        print(f\"Please inspect the columns printed above and set 'sports_text_column' correctly.\")\n",
        "    else:\n",
        "        processed_sports_entries = 0\n",
        "        for index, row in df_sports.iterrows():\n",
        "            article_text = row[sports_text_column]\n",
        "            sentences = segment_into_sentences(article_text)\n",
        "            for sentence in sentences:\n",
        "                all_sentences_and_labels.append({'text': sentence, 'label': 'sports'})\n",
        "            processed_sports_entries += 1\n",
        "        print(f\"Processed {processed_sports_entries} sports articles/entries.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"ERROR: 'pyarrow' or 'fastparquet' might be needed to read parquet files.\")\n",
        "    print(\"Please install it if you haven't: !pip install pyarrow fastparquet\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading or processing sports data: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIlfBjzl-91_"
      },
      "source": [
        "# **CREATING PANDAS DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_j6bXzX_Ch1",
        "outputId": "d878ffa8-12fb-41ba-ee19-2fc4ee79c6a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Combined Dataset ---\n",
            "Total sentences collected: 99243\n",
            "Label distribution:\n",
            "label\n",
            "movie     71532\n",
            "book      26305\n",
            "sports     1406\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First 5 rows of the combined dataset:\n",
            "                                                text  label\n",
            "0  the most consistently effective gag revolves a...  movie\n",
            "1            Glad they didn't sugar coat the ending.   book\n",
            "2  in essence , the entire segment works like a t...  movie\n",
            "3  it basically starts off with keanu uploading i...  movie\n",
            "4  i was hoping for a little more out of jaw mohr...  movie\n"
          ]
        }
      ],
      "source": [
        "if not all_sentences_and_labels:\n",
        "    print(\"No data was processed. The list 'all_sentences_and_labels' is empty.\")\n",
        "    print(\"Please check the file paths and processing logic for your datasets.\")\n",
        "    final_df = pd.DataFrame(columns=['text', 'label']) # create empty DataFrame\n",
        "else:\n",
        "    final_df = pd.DataFrame(all_sentences_and_labels)\n",
        "\n",
        "    # suffle dataframe\n",
        "    final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n--- Combined Dataset ---\")\n",
        "    print(f\"Total sentences collected: {len(final_df)}\")\n",
        "    if not final_df.empty:\n",
        "        print(\"Label distribution:\")\n",
        "        print(final_df['label'].value_counts())\n",
        "        print(\"\\nFirst 5 rows of the combined dataset:\")\n",
        "        print(final_df.head())\n",
        "    else:\n",
        "        print(\"The final DataFrame is empty.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNKOrxzLCYu1"
      },
      "source": [
        "# **PREP DATAFRAME**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MruqPdRbCdKv",
        "outputId": "fe5fa7ea-0df6-41c7-fb9c-f3bb2de1f1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original final_df head:\n",
            "                                                text  label\n",
            "0  the most consistently effective gag revolves a...  movie\n",
            "1            Glad they didn't sugar coat the ending.   book\n",
            "2  in essence , the entire segment works like a t...  movie\n",
            "3  it basically starts off with keanu uploading i...  movie\n",
            "4  i was hoping for a little more out of jaw mohr...  movie\n",
            "\n",
            "Original label counts:\n",
            "label\n",
            "movie     71532\n",
            "book      26305\n",
            "sports     1406\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label to ID mapping: {'movie': 0, 'book': 1, 'sports': 2}\n",
            "ID to Label mapping: {0: 'movie', 1: 'book', 2: 'sports'}\n",
            "Number of unique labels: 3\n",
            "\n",
            "DataFrame prepared for simpletransformers (first 5 rows):\n",
            "                                                text  labels\n",
            "0  the most consistently effective gag revolves a...       0\n",
            "1            Glad they didn't sugar coat the ending.       1\n",
            "2  in essence , the entire segment works like a t...       0\n",
            "3  it basically starts off with keanu uploading i...       0\n",
            "4  i was hoping for a little more out of jaw mohr...       0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# check for final_df\n",
        "if 'final_df' not in globals() or final_df.empty:\n",
        "    print(\"Error: 'final_df' is not defined or is empty. Please complete Step 2 first.\")\n",
        "else:\n",
        "    print(\"Original final_df head:\")\n",
        "    print(final_df.head())\n",
        "    print(f\"\\nOriginal label counts:\\n{final_df['label'].value_counts()}\")\n",
        "\n",
        "    # map label names\n",
        "    unique_labels_list = final_df['label'].unique().tolist()\n",
        "    label2id = {label: i for i, label in enumerate(unique_labels_list)}\n",
        "    id2label = {i: label for i, label in enumerate(unique_labels_list)}\n",
        "    num_labels = len(unique_labels_list)\n",
        "\n",
        "    print(\"\\nLabel to ID mapping:\", label2id)\n",
        "    print(\"ID to Label mapping:\", id2label)\n",
        "    print(f\"Number of unique labels: {num_labels}\")\n",
        "\n",
        "    final_df['labels'] = final_df['label'].map(label2id) # Creates the numerical 'labels' column\n",
        "\n",
        "    df_for_bert = final_df[['text', 'labels']].copy()\n",
        "\n",
        "    print(\"\\nDataFrame prepared for simpletransformers (first 5 rows):\")\n",
        "    print(df_for_bert.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw2H5iOMCmys",
        "outputId": "60005b3e-6cac-4c2d-8f2b-7a3500c3657a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training DataFrame shape: (84356, 2)\n",
            "Evaluation DataFrame shape: (14887, 2)\n",
            "\n",
            "Training DataFrame label distribution:\n",
            "labels\n",
            "0    60802\n",
            "1    22359\n",
            "2     1195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Evaluation DataFrame label distribution:\n",
            "labels\n",
            "0    10730\n",
            "1     3946\n",
            "2      211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if 'df_for_bert' in globals() and not df_for_bert.empty:\n",
        "    # split into training and eval\n",
        "    train_df, eval_df = train_test_split(\n",
        "        df_for_bert,\n",
        "        test_size=0.15,\n",
        "        random_state=42,\n",
        "        stratify=df_for_bert['labels']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining DataFrame shape: {train_df.shape}\")\n",
        "    print(f\"Evaluation DataFrame shape: {eval_df.shape}\")\n",
        "\n",
        "    print(\"\\nTraining DataFrame label distribution:\")\n",
        "    print(train_df['labels'].value_counts())\n",
        "    print(\"\\nEvaluation DataFrame label distribution:\")\n",
        "    print(eval_df['labels'].value_counts())\n",
        "else:\n",
        "    print(\"\\nSkipping train/eval split as df_for_bert is not ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ8goGPMDDYW"
      },
      "source": [
        "# **STEP 4 MODEL CONFIGURATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xZn_33XwDDLx"
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import torch\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMLITWjqDLWB",
        "outputId": "9aba211c-5e8f-42fe-89e2-d29e8b3b224d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Arguments:\n",
            "ClassificationArgs(adafactor_beta1=None, adafactor_clip_threshold=1.0, adafactor_decay_rate=-0.8, adafactor_eps=(1e-30, 0.001), adafactor_relative_step=True, adafactor_scale_parameter=True, adafactor_warmup_init=True, adam_betas=(0.9, 0.999), adam_epsilon=1e-08, best_model_dir='outputs/best_model/', cache_dir='cache_dir/', config={}, cosine_schedule_num_cycles=0.5, custom_layer_parameters=[], custom_parameter_groups=[], dataloader_num_workers=0, do_lower_case=False, dynamic_quantize=False, early_stopping_consider_epochs=False, early_stopping_delta=0.01, early_stopping_metric='eval_loss', early_stopping_metric_minimize=True, early_stopping_patience=3, encoding=None, eval_batch_size=100, evaluate_during_training=True, evaluate_during_training_silent=True, evaluate_during_training_steps=100, evaluate_during_training_verbose=False, evaluate_each_epoch=True, fp16=True, gradient_accumulation_steps=1, learning_rate=4e-05, local_rank=-1, logging_steps=50, loss_type=None, loss_args={}, manual_seed=None, max_grad_norm=1.0, max_seq_length=256, model_name=None, model_type=None, multiprocessing_chunksize=-1, n_gpu=1, no_cache=False, no_save=False, not_saved_args=[], num_train_epochs=3, optimizer='AdamW', output_dir='outputs/', overwrite_output_dir=True, polynomial_decay_schedule_lr_end=1e-07, polynomial_decay_schedule_power=1.0, process_count=8, quantized_model=False, reprocess_input_data=True, save_best_model=True, save_eval_checkpoints=True, save_model_every_epoch=True, save_optimizer_and_scheduler=True, save_steps=2000, scheduler='linear_schedule_with_warmup', silent=False, skip_special_tokens=True, tensorboard_dir=None, thread_count=None, tokenizer_name=None, tokenizer_type=None, train_batch_size=16, train_custom_parameters_only=False, trust_remote_code=False, use_cached_eval_features=False, use_early_stopping=True, use_hf_datasets=False, use_multiprocessing=True, use_multiprocessing_for_evaluation=True, wandb_kwargs={}, wandb_project=None, warmup_ratio=0.06, warmup_steps=0, weight_decay=0.0, model_class='ClassificationModel', labels_list=[], labels_map={}, lazy_delimiter='\\t', lazy_labels_column=1, lazy_loading=False, lazy_loading_start_line=1, lazy_text_a_column=None, lazy_text_b_column=None, lazy_text_column=0, onnx=False, regression=False, sliding_window=False, special_tokens_list=[], stride=0.8, tie_value=1)\n"
          ]
        }
      ],
      "source": [
        "model_args = ClassificationArgs()\n",
        "\n",
        "# main args\n",
        "model_args.num_train_epochs = 3  # train epochs\n",
        "model_args.train_batch_size = 16 # batch size\n",
        "model_args.learning_rate = 4e-5  # learn rate\n",
        "model_args.max_seq_length = 256  # max seq len\n",
        "\n",
        "# eval and saving\n",
        "model_args.evaluate_during_training = True # eval while training\n",
        "model_args.evaluate_during_training_steps = 100 # eval every 100 steps\n",
        "model_args.overwrite_output_dir = True    # overwrite in output dir\n",
        "model_args.output_dir = \"outputs/\"        # dir to save\n",
        "model_args.best_model_dir = \"outputs/best_model/\" # special dir for best model\n",
        "\n",
        "# early stopping\n",
        "model_args.use_early_stopping = True\n",
        "model_args.early_stopping_delta = 0.01\n",
        "model_args.early_stopping_metric = 'eval_loss'\n",
        "model_args.early_stopping_metric_minimize = True\n",
        "model_args.early_stopping_patience = 3 # nr of evals for improving\n",
        "\n",
        "print(\"Model Arguments:\")\n",
        "print(model_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2xkkEI4DPJc",
        "outputId": "1e934ad2-a9a5-412f-ca8b-56eaf1c3b008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU not available. Setting use_cuda=False.\n",
            "Number of labels for the model: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ClassificationModel initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "# check for GPU\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print(\"GPU is available. Setting use_cuda=True.\")\n",
        "else:\n",
        "    print(\"GPU not available. Setting use_cuda=False.\")\n",
        "\n",
        "if 'num_labels' not in globals():\n",
        "    print(\"Error: 'num_labels' is not defined. Please ensure Step 3 (Data Preparation) was completed successfully.\")\n",
        "else:\n",
        "    print(f\"Number of labels for the model: {num_labels}\")\n",
        "    try:\n",
        "        model = ClassificationModel(\n",
        "            model_type='bert',\n",
        "            model_name='bert-base-uncased', # model usde\n",
        "            num_labels=num_labels,\n",
        "            args=model_args,\n",
        "            use_cuda=use_cuda # using GPU\n",
        "        )\n",
        "        print(\"\\nClassificationModel initialized successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing ClassificationModel: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFBenozMINmm"
      },
      "source": [
        "# **TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9365b9e6c91f4ca48a689bd70208e8b2",
            "11b672e7c1f84973b76cc5814a5b5aa9",
            "1edcedfaf5dd4d8885b5aebbd319489c",
            "9eefeaf69f8141deba85b3275b794bca",
            "62ed5808a8184fd4a7fc35a8b60aa7c8",
            "f0662693777740389e3c5c3fcbac3199",
            "aee63a13f11d4761bb2d7102296a901b",
            "75dc8292ad9740988028471c25bd00c1",
            "7fe831a0053c4fd3805ef95cc640c3c1",
            "5489dae597d44d819ed0023bcf54984d",
            "e89fd5ba766b4531b3a29c3a31259374"
          ]
        },
        "id": "untH9vxDIM0G",
        "outputId": "8bea3fe9-987e-4c70-d3a4-a08037041eee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/168 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "169it [00:10, 15.67it/s]                         \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_256_3_2\n",
            "Epoch 1 of 3:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  3.84it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  4.06it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  3.99it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  4.27it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "TOKENIZERS_PARALLELISMTo disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable =(true | false)\n",
            "TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  4.13it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 2\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.56it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:07,  4.00it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.42it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 2\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.37it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.38it/s]\n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.58it/s]\n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.48it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.61it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 2\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.52it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
            "INFO:simpletransformers.classification.classification_model: Current step: 3\n",
            "INFO:simpletransformers.classification.classification_model: Early stopping patience: 3\n",
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
            "\n",
            "\u001b[Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "30it [00:06,  4.56it/s]                        \n",
            "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_256_3_2\n",
            "INFO:simpletransformers.classification.classification_model: Patience of 3 steps reached\n",
            "INFO:simpletransformers.classification.classification_model: Training terminated.\n",
            "Epoch 1 of 3:   0%|          | 0/3 [4:24:24<?, ?it/s]\n",
            "Epochs 1/3. Running Loss:    0.0087:  28%|       | 1499/5273 [4:24:24<11:05:42, 10.58s/it]\n",
            "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to outputs/.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training complete.\n",
            "Training history (includes training and evaluation losses per logging step):\n",
            "Evaluation results during training:\n",
            "{'mcc': 0.8801801371878566, 'eval_loss': 0.16240851521091973}\n"
          ]
        }
      ],
      "source": [
        "if 'model' in globals() and 'train_df' in globals() and 'eval_df' in globals():\n",
        "    print(\"Starting model training...\")\n",
        "\n",
        "    _, training_history = model.train_model(\n",
        "        train_df,\n",
        "        eval_df=eval_df\n",
        "    )\n",
        "\n",
        "    print(\"Model training complete.\")\n",
        "    print(\"Training history (includes training and evaluation losses per logging step):\")\n",
        "\n",
        "    if hasattr(model, 'results'):\n",
        "        print(\"Evaluation results during training:\")\n",
        "        print(model.results)\n",
        "\n",
        "else:\n",
        "    print(\"Error: 'model', 'train_df', or 'eval_df' is not defined. Please complete previous steps.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: 'best_model' not loaded. Attempting to use the 'model' from the training step.\n",
            "\n",
            "Successfully loaded official test set from: sentiment-topic-test.tsv\n",
            "Official test set shape: (18, 4)\n",
            "   sentence_id                                           sentence sentiment  \\\n",
            "0            0  The stadium was alive with the roar of the cro...  positive   \n",
            "1            1  That last-minute goal had me jumping out of my...  positive   \n",
            "2            2  I couldnt put the book down; it swept me into...  positive   \n",
            "3            3  The story had its moments, though some parts f...   neutral   \n",
            "4            4  I enjoyed the way the timelines shifted, even ...   neutral   \n",
            "\n",
            "    topic  \n",
            "0  sports  \n",
            "1  sports  \n",
            "2    book  \n",
            "3    book  \n",
            "4    book  \n",
            "\n",
            "Predicting on official test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "1it [00:05,  5.10s/it]\n",
            "100%|| 1/1 [00:00<00:00,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report on Official Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       movie       0.75      1.00      0.86         6\n",
            "        book       1.00      1.00      1.00         6\n",
            "      sports       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.89        18\n",
            "   macro avg       0.92      0.89      0.89        18\n",
            "weighted avg       0.92      0.89      0.89        18\n",
            "\n",
            "\n",
            "Official test set with predictions (first 5 rows):\n",
            "   sentence_id                                           sentence sentiment  \\\n",
            "0            0  The stadium was alive with the roar of the cro...  positive   \n",
            "1            1  That last-minute goal had me jumping out of my...  positive   \n",
            "2            2  I couldnt put the book down; it swept me into...  positive   \n",
            "3            3  The story had its moments, though some parts f...   neutral   \n",
            "4            4  I enjoyed the way the timelines shifted, even ...   neutral   \n",
            "\n",
            "    topic  predicted_numerical_label predicted_topic_string  \n",
            "0  sports                          2                 sports  \n",
            "1  sports                          2                 sports  \n",
            "2    book                          1                   book  \n",
            "3    book                          1                   book  \n",
            "4    book                          1                   book  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "if 'best_model' not in globals():\n",
        "    print(\"Warning: 'best_model' not loaded. Attempting to use the 'model' from the training step.\")\n",
        "    if 'model' in globals():\n",
        "        eval_model_for_test = model\n",
        "    else:\n",
        "        print(\"Error: No trained model available for test set evaluation.\")\n",
        "        eval_model_for_test = None \n",
        "else:\n",
        "    eval_model_for_test = best_model\n",
        "\n",
        "# test set\n",
        "test_set_path = 'sentiment-topic-test.tsv' \n",
        "\n",
        "if eval_model_for_test and 'label2id' in globals() and 'id2label' in globals() and 'num_labels' in globals():\n",
        "    try:\n",
        "        df_official_test = pd.read_csv(test_set_path, sep='\\t')\n",
        "        print(f\"\\nSuccessfully loaded official test set from: {test_set_path}\")\n",
        "        print(f\"Official test set shape: {df_official_test.shape}\")\n",
        "        print(df_official_test.head()) \n",
        "\n",
        "        test_sentences = df_official_test['sentence'].tolist()\n",
        "        true_topic_strings = df_official_test['topic'].tolist()\n",
        "\n",
        "        # convert true topic strings to numerical IDs using the SAME label2id from training\n",
        "        true_numerical_labels = [label2id[label] for label in true_topic_strings]\n",
        "\n",
        "        print(\"\\nPredicting on official test set...\")\n",
        "        predicted_numerical_labels, raw_outputs = eval_model_for_test.predict(test_sentences)\n",
        "        \n",
        "        print(\"\\nClassification Report on Official Test Set:\")\n",
        "        # making sure target names are in correct order for nr lables\n",
        "        target_names_ordered = [id2label[i] for i in range(num_labels)]\n",
        "        print(classification_report(true_numerical_labels, predicted_numerical_labels, target_names=target_names_ordered))\n",
        "\n",
        "        # add the predictions back to the DataFrame for analysis\n",
        "        df_official_test['predicted_numerical_label'] = predicted_numerical_labels\n",
        "        df_official_test['predicted_topic_string'] = [id2label[pred] for pred in predicted_numerical_labels]\n",
        "        print(\"\\nOfficial test set with predictions (first 5 rows):\")\n",
        "        print(df_official_test.head())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Official test file not found at {test_set_path}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"ERROR: A required column is missing or a label in the test set was not in the training data's label2id map: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during official test set evaluation: {e}\")\n",
        "else:\n",
        "    print(\"\\nError: Model or label mappings not ready for official test set evaluation.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11b672e7c1f84973b76cc5814a5b5aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0662693777740389e3c5c3fcbac3199",
            "placeholder": "",
            "style": "IPY_MODEL_aee63a13f11d4761bb2d7102296a901b",
            "value": "9%"
          }
        },
        "1edcedfaf5dd4d8885b5aebbd319489c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75dc8292ad9740988028471c25bd00c1",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fe831a0053c4fd3805ef95cc640c3c1",
            "value": 15
          }
        },
        "5489dae597d44d819ed0023bcf54984d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ed5808a8184fd4a7fc35a8b60aa7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dc8292ad9740988028471c25bd00c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe831a0053c4fd3805ef95cc640c3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9365b9e6c91f4ca48a689bd70208e8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b672e7c1f84973b76cc5814a5b5aa9",
              "IPY_MODEL_1edcedfaf5dd4d8885b5aebbd319489c",
              "IPY_MODEL_9eefeaf69f8141deba85b3275b794bca"
            ],
            "layout": "IPY_MODEL_62ed5808a8184fd4a7fc35a8b60aa7c8"
          }
        },
        "9eefeaf69f8141deba85b3275b794bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5489dae597d44d819ed0023bcf54984d",
            "placeholder": "",
            "style": "IPY_MODEL_e89fd5ba766b4531b3a29c3a31259374",
            "value": "15/168[00:03&lt;00:32,4.71it/s]"
          }
        },
        "aee63a13f11d4761bb2d7102296a901b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e89fd5ba766b4531b3a29c3a31259374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0662693777740389e3c5c3fcbac3199": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
